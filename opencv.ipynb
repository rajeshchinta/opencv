{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 623, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('lambo.png')\n",
    "print(img.shape)\n",
    "\n",
    "imgResize = cv2.resize(img,(300,200))\n",
    "\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.imshow(\"Resized Image\",imgResize)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing line, circle, Rectangle, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "print(img.shape)\n",
    "\n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]), (0,0,255),3)\n",
    "cv2.rectangle(img, (0,0),(250,250), (0,0,255),2)\n",
    "cv2.circle(img, (125,125), 80, (0,0,255),2)\n",
    "cv2.putText(img, \"Rajesh\", (250,100), cv2.FONT_HERSHEY_TRIPLEX,2, (0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('cards.jpg')\n",
    "\n",
    "width, height = 250, 350\n",
    "\n",
    "pts1 = np.float32([[111,219], [287,188], [154,482], [352,440]])\n",
    "pts2 = np.float32([[0,0], [width,0], [0,height],[width,height]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "imgOutput = cv2.warpPerspective(img, matrix, (width,height))\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('Output Image', imgOutput)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours / Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours / shape detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getContours(img):\n",
    "    # Finding How many countors(objects) in a image\n",
    "    contours, heirarchy = cv2.findContours(imgCanny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # print(area)\n",
    "        # This is just simply if the area is grreater than 300 then drawing contours\n",
    "        if area > 1000:\n",
    "            # -1 indicated draw all the contours\n",
    "            cv2.drawContours(imgContour,cnt,-1,(255,255,0),3)\n",
    "            # True is to determine it's a closesd contor\n",
    "            # finding the curve length used to approximated the edges(corners)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            # Approximating how many cornor points we have\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            # print(approx) -- it will give the corner points of each shape\n",
    "            # len(approx) -- if one of the shape having 3 corners then we will determine it as Rectangle\n",
    "            objCor = len(approx)\n",
    "            \n",
    "            # Getting the boundary boxes of each object and\n",
    "            # Drawing a bounding box at each of the object detected\n",
    "            x,y,w,h = cv2.boundingRect(approx)\n",
    "            if objCor == 3: objectType = 'Tri'\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio > 0.95 and aspRatio < 1.05: objectType = \"Square\"\n",
    "                else: objectType = \"Rectangle\"\n",
    "            elif objCor > 4: objectType = \"circle\"\n",
    "            else: objectType = \"None\"\n",
    "            cv2.rectangle(imgContour, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "            # From these bounding boxes we can get the total width, height and center point of the object\n",
    "            cv2.putText(imgContour,objectType, \n",
    "                        (x+(w//2)-10, y+(h//2)-10),\n",
    "                        cv2.FONT_HERSHEY_COMPLEX,\n",
    "                        0.5, (0,0,0),2)\n",
    "\n",
    "img = cv2.imread('shapes.png')\n",
    "imgContour = img.copy()\n",
    "\n",
    "# First strp is to preprocess the image\n",
    "# convert the image to gray scale and then find the edges\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detecting the Edges\n",
    "imgCanny = cv2.Canny(imgGray,50,50)\n",
    "\n",
    "getContours(imgCanny)\n",
    "\n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.imshow(\"Gray image\",imgGray)\n",
    "cv2.imshow(\"Canny image\",imgCanny)\n",
    "cv2.imshow(\"Contour image\",imgContour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as npf\n",
    "\n",
    "widthImg = 640\n",
    "heightImg = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, widthImg)\n",
    "cap.set(4, heightImg)\n",
    "cap.set(10, 130)\n",
    "\n",
    "\n",
    "def preProcessing(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray,(5,5),1)\n",
    "    imgCanny = cv2.Canny(imgBlur, 50,50)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    imgDial = cv2.dilate(imgCanny,kernel, iterations=2)\n",
    "    imgThres = cv2.erode(imgDial, kernel, iterations=1)\n",
    "    return imgThres\n",
    "\n",
    "def getContours(img):\n",
    "    biggest = np.array([])\n",
    "    maxArea = 0\n",
    "    contours, heir = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # print(area)\n",
    "        if area > 1000:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255,0,0),3)\n",
    "            peri = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)\n",
    "            if area > maxArea and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                maxArea = area\n",
    "    cv2.drawContours(imgContour, biggest, -1, (255,0,0),20)\n",
    "    return biggest\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.resize(img, (widthImg, heightImg))\n",
    "    imgContour = img.copy()\n",
    "    \n",
    "    imgThres = preProcessing(img)\n",
    "    biggest = getContours(imgThres)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Result\", imgContour)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('early_1800.jpg')\n",
    "imgBlur = cv2.GaussianBlur(img, (5,5),1)\n",
    "blur = cv2.blur(img,(5,5))\n",
    "\n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.imshow(\"Blur Image\",imgBlur)\n",
    "cv2.imshow(\"Blur\",blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('balloons_noisy.png')\n",
    "averaging = cv2.blur(img,(5,5))\n",
    "gaussina = cv2.GaussianBlur(img, (5,5),1)\n",
    "median = cv2.medianBlur(img,5)\n",
    "\n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.imshow(\"averagring\",averaging)\n",
    "cv2.imshow(\"Gaussian\",gaussina)\n",
    "cv2.imshow(\"Median\",median)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('balloons_noisy.png')\n",
    "averaging = cv2.blur(img,(5,5))\n",
    "gaussina = cv2.GaussianBlur(img, (5,5),1)\n",
    "median = cv2.medianBlur(img,5)\n",
    "bilateral = cv2.bilateralFilter(img, 5, 75,75) # 75 & 75 is just to keep the edges\n",
    "\n",
    "cv2.imshow(\"Original\",img)\n",
    "# cv2.imshow(\"averagring\",averaging)\n",
    "# cv2.imshow(\"Gaussian\",gaussina)\n",
    "cv2.imshow(\"Median\",median)\n",
    "# cv2.imshow(\"bilateral\",bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('gradient.jpg',0)\n",
    "# Binary have only 1 and 0 that means pixel less than thres = 0 else 1\n",
    "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
    "\n",
    "# ThresThe pixel value upto threshold wont change and after threshold, if the pixel is greater thaan or lower it will change to threshold value\n",
    "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
    "\n",
    "# pixel less than trun = 0 and if greater than trun it remains same\n",
    "ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.imshow(\"Binary\",thresh1)\n",
    "cv2.imshow(\"Binary Inverse\",thresh2)\n",
    "cv2.imshow(\"TRUN\",thresh3)\n",
    "cv2.imshow(\"TOZERO\",thresh4)\n",
    "cv2.imshow(\"TOZERO INVERSE\",thresh5)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Transformation\n",
    "### Erosion, Dilation, Opening & Closing\n",
    "Opening: Erosion -> Dilation <br>\n",
    "Closing: Dilation -> Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((9,3),np.uint8)\n",
    "kernel1 = np.ones((3,3),np.uint8)\n",
    "\n",
    "img = cv.imread('T.png')\n",
    "erosion = cv.erode(img, kernel, iterations=1)\n",
    "dilation = cv.dilate(img, kernel, iterations=1)\n",
    "# opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n",
    "# closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n",
    "# final = cv.erode(dilation, kernel, iterations=1)\n",
    "\n",
    "# averaging = cv.blur(final,(5,5))\n",
    "# gaussina = cv.GaussianBlur(final, (5,5),1)\n",
    "# median = cv.medianBlur(final,5)\n",
    "# bilateral = cv.bilateralFilter(final, 5, 75,75) \n",
    "\n",
    "# cv.imshow(\"average\", averaging)\n",
    "# cv.imshow(\"gaussina\", gaussina)\n",
    "# cv.imshow(\"median\", median)\n",
    "# cv.imshow(\"bilateral\", bilateral)\n",
    "\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Dilation\", dilation)\n",
    "# cv.imwrite(\"temp/Dilation39.png\", dilation)\n",
    "cv.imshow(\"Erosion\", erosion)\n",
    "# cv.imshow(\"final\", final)\n",
    "# cv.imshow(\"opening\", opening)\n",
    "# cv.imshow(\"closing\", closing)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "v_kernel = np.ones((3,9),np.uint8)\n",
    "h_kernel = np.ones((9,3),np.uint8)\n",
    "# kernel1 = np.ones((3,3),np.uint8)\n",
    "\n",
    "img = cv.imread('table.jpg')\n",
    "# erosion = cv.erode(img, kernel, iterations=1)\n",
    "dilation1 = cv.dilate(img, v_kernel, iterations=1)\n",
    "dilation2 = cv.dilate(img, h_kernel, iterations=1)\n",
    "# opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)\n",
    "# closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)\n",
    "# final = cv.erode(dilation, kernel, iterations=1)\n",
    "\n",
    "# averaging = cv.blur(final,(5,5))\n",
    "# gaussina = cv.GaussianBlur(final, (5,5),1)\n",
    "# median = cv.medianBlur(final,5)\n",
    "# bilateral = cv.bilateralFilter(final, 5, 75,75) \n",
    "\n",
    "# cv.imshow(\"average\", averaging)\n",
    "# cv.imshow(\"gaussina\", gaussina)\n",
    "# cv.imshow(\"median\", median)\n",
    "# cv.imshow(\"bilateral\", bilateral)\n",
    "\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Horizontal Lines\", dilation1)\n",
    "cv.imshow(\"Vertical Lines\", dilation2)\n",
    "# cv.imwrite(\"temp/Dilation39.png\", dilation)\n",
    "# cv.imshow(\"Erosion\", erosion)\n",
    "# cv.imshow(\"final\", final)\n",
    "# cv.imshow(\"opening\", opening)\n",
    "# cv.imshow(\"closing\", closing)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image: table.jpg\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "v_kernel = np.ones((3,9),np.uint8)\n",
    "h_kernel = np.ones((9,3),np.uint8)\n",
    "\n",
    "img = cv.imread('table.jpg')\n",
    "# erosion = cv.erode(img, kernel, iterations=1)\n",
    "dilation1 = cv.dilate(img, v_kernel, iterations=1)\n",
    "dilation2 = cv.dilate(img, h_kernel, iterations=1)\n",
    "\n",
    "cv.imshow(\"Original\", img)\n",
    "cv.imshow(\"Horizontal Lines\", dilation1)\n",
    "cv.imshow(\"Vertical Lines\", dilation2)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding Boxes (IEEE Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"pdf_page.jpg\")\n",
    "imgContour = img.copy()\n",
    "imgGray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "blur = cv.GaussianBlur(imgGray, (5,5),0)\n",
    "# thres = cv.threshold(blur, 0, 255, cv.THRESH_BINARY_INV+cv.THRESH_OTSU)[1]\n",
    "\n",
    "bit = cv.bitwise_not(blur)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "dilate = cv.dilate(bit, kernel, iterations=1)\n",
    "\n",
    "contour = cv.findContours(dilate, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)[0]\n",
    "for cnt in contour:\n",
    "    peri = cv.arcLength(cnt,True)\n",
    "    approx = cv.approxPolyDP(cnt, 0.02*peri, True)\n",
    "    x,y,w,h = cv.boundingRect(approx)\n",
    "    if w > 50 and h > 100:\n",
    "        cv.rectangle(imgContour, (x,y), (x+w,y+h), (0,255,0),2)\n",
    "    # cv.drawContours(imgContour, cnt, -1, (255,0,0),3)\n",
    "\n",
    "# cv.imshow(\"Image\",img)\n",
    "# cv.imshow(\"Blur\",blur)\n",
    "cv.imshow(\"bit\",dilate)\n",
    "cv.imshow(\"Contour\",imgContour)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Detection From Image\n",
    "### Detecting Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread('text.png')\n",
    "\n",
    "h_img, w_img,_ = img.shape\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# It will detect the text and return it (not position)\n",
    "# print(pytesseract.image_to_string(imgGray))\n",
    "\n",
    "# it will give the eachh word with x,y,w,h position\n",
    "boxes = pytesseract.image_to_boxes(imgGray)\n",
    "for box in boxes.splitlines():\n",
    "    b = box.split(' ')\n",
    "    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])\n",
    "    # print(x,y,w,h)\n",
    "    cv2.rectangle(img, (x,h_img-y), (w,h_img-h), (0,0,255),2)\n",
    "    cv2.putText(img, b[0],(x,h_img-y+20),cv2.FONT_HERSHEY_COMPLEX,0.5,(50,50,255),1)\n",
    "    \n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "# cv2.imshow(\"Image\",imgGray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level\tpage_num\tblock_num\tpar_num\tline_num\tword_num\tleft\ttop\twidth\theight\tconf\ttext\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t742\t347\t-1\t\n",
      "2\t1\t1\t0\t0\t0\t164\t66\t377\t40\t-1\t\n",
      "3\t1\t1\t1\t0\t0\t164\t66\t377\t40\t-1\t\n",
      "4\t1\t1\t1\t1\t0\t164\t66\t377\t40\t-1\t\n",
      "5\t1\t1\t1\t1\t1\t164\t66\t171\t40\t96.429344\tRAJESH\n",
      "5\t1\t1\t1\t1\t2\t355\t67\t186\t38\t96.163536\tVARMA\n",
      "2\t1\t2\t0\t0\t0\t73\t217\t596\t40\t-1\t\n",
      "3\t1\t2\t1\t0\t0\t73\t217\t596\t40\t-1\t\n",
      "4\t1\t2\t1\t1\t0\t73\t217\t596\t40\t-1\t\n",
      "5\t1\t2\t1\t1\t1\t73\t217\t596\t40\t0.000000\t1234567891011\n",
      "5\t1\t2\t1\t1\t2\t602\t213\t67\t61\t0.000000\t12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread('text.png')\n",
    "\n",
    "h_img, w_img,_ = img.shape\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# It will detect the text and return it (not position)\n",
    "# print(pytesseract.image_to_string(imgGray))\n",
    "\n",
    "# it will give the each character with x,y,w,h position\n",
    "boxes = pytesseract.image_to_data(imgGray)\n",
    "print(boxes)\n",
    "for i,box in enumerate(boxes.splitlines()):\n",
    "    if i != 0: # Eliminating the Header\n",
    "        b = box.split()\n",
    "        if len(b) == 12:\n",
    "            x,y,w,h = int(b[6]),int(b[7]),int(b[8]),int(b[9])\n",
    "            # print(x,y,w,h)\n",
    "            cv2.rectangle(img, (x,y), (w+x,h+y), (0,0,255),2)\n",
    "            cv2.putText(img, b[11],(x,y),cv2.FONT_HERSHEY_COMPLEX,0.5,(50,50,255),1)\n",
    "            \n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "# cv2.imshow(\"Image\",imgGray)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aed9c9c962d10c46db004ed877b9b8537276cd8e1aa94e280d781901ce76e3c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
